Chapter 8: Hierarchical model construction
===============================

## Big picture
Translating problems to models is a key skill, and it may take a fair bit of practice. 
In this chapter we introduce tools to help with this step: parameter, process, and observation models, and a few examples that make use of familiar probability distributions.

#### Learning goals
- building models from simple submodels
- parameter, process, and observation models
- examples:  
-- occupancy model  
-- N-mixture model  
-- error in variables models

## Parameter, process, and observation models

One incredibly powerful perspective in model construction is the distinction between observation, process, and parameter models. 
The observation model includes the likelihood, and relates the latent process of interest to the quantities that we have actually observed. 
The process model is typically what we're most interested in scientifically, and typically is not fully observed. 
The parameter model includes any hierarchical structures on parameters and priors for hyperparameters. 

Depending on the nature of any particular problem, it may be advantageous to begin model formulation at different levels. 
For instance, if there is a specific biological process that one has in mind, but it is not clear what sources of data will be necessary, it might be useful to first construct the process model and then think about what sources of information are needed to estimate the process parameters. 
In other situations, the process based model may be simple or known ahead of time, but a model must make use of vastly different sources of data. 
In these cases, it may be more useful to begin by developing an observation model. 

### Example: occupancy model

Occupancy models represent the presence or absence of a species from a location as a Bernoulli random variable $Z$, with $z=0$ corresponding to absence and $z=1$ corresponding to presence. 
If the species is present $z=1$, it will be detected on a survey with probability $p$.
So, species may be present but undetected. 
If a species is absent, it will not be detected (we assume no false detections), but species may be present and undetected. 

We can write this as a hierarchical model with occurrence state $z$ treated as a binary latent (hidden) variable: 

$$[z \mid \psi] \sim Bernoulli(\psi)$$

$$[y \mid z, p] \sim Bernoulli(z p)$$

The observation model is $[y \mid z, p]$, and the process model is $[z \mid \psi]$.

If we wish to avoid the use of a discrete parameter, we can marginalize $z$ out of the posterior distribution by summing over all possible values (in this case, just 0 and 1):

$$[\psi, p \mid y] \propto \sum_z [y \mid z, p] [z \mid \psi] [p, \psi]$$

$$[\psi, p \mid y] \propto  [p, \psi] \sum_z [y \mid z, p] [z \mid \psi]$$

$$[\psi, p \mid y] \propto  [p, \psi] \big( [y \mid z=1, p] [z=1 \mid \psi] + [y \mid z=0, p] [z=0 \mid \psi] \big)$$

$$[\psi, p \mid y] \propto  [p, \psi] \big( \psi Bernoulli(p) + (1-\psi) I(y = 0)  \big)$$

where $I(y = 0)$ is an identity function that sets $y$ to zero because we assumed that there are no false detections when the species is absent. 
Multiple surveys are necessary to identify $\psi$ and $p$, so that we can expand the likelihood to account of binomial observation histories, with $k$ surveys conducted per site, and observation history vectors $y_i$ for the $i^{th}$ site:

$$[y_i \mid \psi_i, p_i] \begin{cases} \psi_i Binom(y_i, k) &\mbox{if } \sum y_i > 0 \\ 
\psi_i Binom(0, k) + (1 - \psi) & otherwise \end{cases}$$

If the organism was observed, then we know that any non-detections represent false absences. 
If the organism was not observed, then it was either there and not observed (with probability $\psi_i Binom(0, k)$) or it was not there with probability $1 - \psi$. 
This if-else structure can be exploited in Stan to implement this likelihood:

```
data { 
   int<lower=0> nsite; 
   int<lower=0> nsurvey; 
   int<lower=0,upper=1> y[nsite,nsurvey]; 
} 
parameters { 
   real<lower=0,upper=1> psi; 
   real<lower=0,upper=1> p; 
} 
model { 
   for (i in 1:nsite) { 
     if (sum(y[i]) > 0)
       // species was observed: it is there
       increment_log_prob(log(psi) + bernoulli_log(y[i],p)); 
     else 
       // it may or may not be there
       increment_log_prob(log_sum_exp(log(psi) + bernoulli_log(y[i],p), 
                                      log1m(psi))); 
   } 
} 
```

Now let's simulate some occupancy data and fit the model:

```{r, message=FALSE, warnings=FALSE, results='hide'}
nsite <- 50
nsurvey <- 3
psi <- .4
p <- .8
z <- rbinom(nsite, 1, psi)
y <- matrix(rbinom(nsite * nsurvey, 1, z * p), 
            nrow=nsite)

stan_d <- list(nsite = nsite, 
               nsurvey = nsurvey, 
               y = y)
out <- stan('occupancy.stan', data = stan_d)
```

How did we do? 

```{r, fig.cap="Traceplot of the Markov chains from the occupancy model."}
out
traceplot(out)
```

```{r, fig.cap="Posterior densities for occupancy and detection probabilities along with their known true values."}
par(mfrow=c(1, 2))
post <- extract(out)
plot(density(post$psi), main=expression(psi))
abline(v=psi, col='red', lwd=2)
plot(density(post$p), main='p')
abline(v=p, col='red', lwd=2)
```

The parameter-level model can be extended to include covariates for $\psi$ and $p$ by making use of a link function and design matrices. 

### Example: N-mixture model

We are often interested in estimating and explaining population sizes in wild organisms, and mark-recapture methods are not always feasible. 
Suppose we visit site $i$ multiple times $j=1, ..., J$, and on each visit we conduct a survey, recording the number of individuals observed.
If we can assume that across visits, the true abundance $N_i$ is unchanged, and that the detection of each individual is imperfect but independent, then we might construct an N-mixture model to estimate abundance. 

**Observation model**

We observe a subset of the individuals at the site, and each individual is detected with probability $p_i$:

$$y_{ij} \sim Binom(N_i, p_i)$$

Notice that both parameters of the binomial observation model are unknown. 
True abundance $N_i$ is a latent quantity.

**Process model**

We need some discrete probability distribution for $N$, such as the Poisson or negative binomial. 

$$N_i \sim Pois(\lambda_i)$$

**Parameter model**

Finally, we need priors for $p$ and $\lambda$.

$$p \sim ...$$

$$\lambda \sim ...$$

We note that this model has integer parameters, and as such cannot be fitted (presently) with Stan, but this is easy to implement in JAGS. 

### Example: error in variables models

Most of the time in ecology, covariates are observed with error and subsequently assumed to be known exactly. 
This causes bias in slope estimates, and despite the fact that this has been known for over a century, most people carry on assuming that the covariate is fixed. 

For what follows, we'll assume a simple linear regression, in which continuous covariates are measured with error. 
But, this approach can be applied to any of the models that we've covered in this class.

True covariate values are considered latent variables, with repeated measurements of covariate values $x_{i=1}, ..., x_{i=n}$ arising from a normal distribution with a mean equal to the true value, and some measurement error $\sigma_x$.
Again, this is a special case, but in principle the covariate could have other distributions (e.g., you're interested in the effect of sex (M or F), but this is measured imperfectly).

**Observation model**

We assume that for sample unit $i$ and repeat measurement $j$:

$$ x^{obs}_{ij} \sim Normal(x_i, \sigma_x) $$

$$ y \sim Normal(\mu_y, \sigma_y) $$

The trick here is to use repeated measurements of the covariates to estimate and correct for measurement error.
In order for this to be valid, the true covariate values cannot vary across repeat measurements.
If the covariate was individual weight, you would have to ensure that the true weight did not vary across repeat measurements (for me, frogs urinating during handling would violate this assumption).

**Process model**

This is what we're typically interested in: how the expected value of $y$ varies with $x$. 
In this case, $x$ is a parameter (it will require a prior).

$$\mu_y = \alpha + \beta x_i$$

**Parameter model**

In the parameter model, we would specify priors for $x$, $\alpha$, $\beta$, and the variance parameters. 
More on this example can be found [here](http://mbjoseph.github.io/2013/11/27/measure.html). 

## General strategies for model building

### Verify your model

It is always a good idea to verify your model, meaning to ensure that the estimation procedure is reliable. 
One way to do this is with simulated data. 
In particular, simulating data from a known generative model, and then trying to recover the parameters can give you insights into a) whether your model even works, b) the behavior of the MCMC algorithm, and c) the frequentist properties of your estimate (long-run interval coverage, bias). 
In addition, this procedure gives you piece of mind. 
It is also often useful to investigate the implications of and sensitivity to model misspecification in this context, where there are known differences between the generative model and the statistical model.
In my experience this excercise nearly always proves to be incredibly useful.

### Start simple

Too often, people charge forward and build incredibly elaborate hierarchical Bayesian models, only to find that they don't work in some way (either they don't converge, recover parameters, take too long, etc.). 
Instead, start with simple models. 
Add complexity incrementally. 
That way, when something breaks, you will be more likely to know what model component is causing the problem. 
This also helps to clarify thinking about what complexity can be safely ignored, and what must be included in the model. 

### Stay simple

It's easy to build incredibly complex models, but simple models are sometimes more powerful. 
Also, simple models are more likely to be broadly applicable to other systems, whereas an incredibly complicated model might only apply to your system. 
In papers, simple models are much easier to explain as well.

## Further reading

Gelman and Hill. 2009. *Data analysis using regression and multilevel/hierarchical models*. Chapter 14 & 15.

Royle JA. N-mixture models for estimating population size from spatially replicated counts. Biometrics 60. 
